{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10740e78-4234-4f3b-bccb-abfd87f0f48d",
   "metadata": {},
   "source": [
    "# 4.Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9d9440-52d5-4355-a280-6dedd9397a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "sys.path.append('../config')  \n",
    "from model_config import ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7411918f-6df3-4962-9add-90a6b46cbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scalers\n",
    "scaler_X = joblib.load('../models/scaler_X.pkl')\n",
    "scaler_y = joblib.load('../models/scaler_y.pkl')\n",
    "\n",
    "# Load normalized data\n",
    "normalized_data = joblib.load('../models/normalized_data.pkl')\n",
    "X_normalized = normalized_data['X_normalized']\n",
    "y_normalized = normalized_data['y_normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0414c7-1628-4fd9-ba2f-0fc83fc81a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create sequences for time series prediction\n",
    "def create_sequences(X, y, time_steps= ModelConfig.TIME_STEPS):\n",
    "    \"\"\"\n",
    "    Create sequences for time series prediction\n",
    "    Args:\n",
    "        X: Input features DataFrame\n",
    "        y: Target values\n",
    "        time_steps: Number of time steps to look back\n",
    "    Returns:\n",
    "        Arrays of sequences for X and y\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X.iloc[i:(i + time_steps)].values)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc8539d-d830-4347-bf66-1a0c4a5c46ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input sequences: (4630, 30, 4)\n",
      "Shape of the output sequences: (4630, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create sequences\n",
    "X_seq, y_seq = create_sequences(X_normalized, y_normalized, ModelConfig.TIME_STEPS)\n",
    "print(\"Shape of the input sequences:\", X_seq.shape)\n",
    "print(\"Shape of the output sequences:\", y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56bdafd8-40a9-4f0d-86b4-be73a7618513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_size = int(len(X_seq) * ModelConfig.TRAIN_SPLIT)\n",
    "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
    "y_train, y_test = y_seq[:train_size], y_seq[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae3a1c24-7c65-47ca-b2ab-5ba8083909da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (3704, 30, 4)\n",
      "Testing Data Shape: (926, 30, 4)\n",
      "Training Labels Shape: (3704, 1)\n",
      "Testing Labels Shape: (926, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Testing Data Shape:\", X_test.shape)\n",
    "print(\"Training Labels Shape:\", y_train.shape)\n",
    "print(\"Testing Labels Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494a08d-480e-4fbe-ae70-4b1d8e00e4a4",
   "metadata": {},
   "source": [
    "# 4.1 LSTM Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a11e5d6-54b8-4bee-b8b8-966520ae7dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 20:54:01.186684: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#Create LSTM model\n",
    "def create_lstm_model(input_shape, units=[64, 32], dropout=0.5):\n",
    "    \"\"\"\n",
    "    Create LSTM model with original configuration\n",
    "    Args:\n",
    "        input_shape: Shape of input data (TIME_STEPS, features)\n",
    "        units: List of units for LSTM layers [default: [64, 32]]\n",
    "        dropout: Dropout rate [default: 0.5]\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM layer with return sequences\n",
    "    model.add(LSTM(\n",
    "        units[0],\n",
    "        return_sequences=True,\n",
    "        activation=ModelConfig.MODEL_PARAMS['activation'],\n",
    "        recurrent_activation=ModelConfig.MODEL_PARAMS['recurrent_activation'],\n",
    "        input_shape=input_shape\n",
    "    ))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(units[1]))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b50bc1-8067-4c0c-9e15-4b7187029f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mxq/.pyenv/versions/my-env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = create_lstm_model(\n",
    "    input_shape=(ModelConfig.TIME_STEPS, X_train.shape[2]),\n",
    "    units=ModelConfig.MODEL_PARAMS['units'],\n",
    "    dropout=ModelConfig.MODEL_PARAMS['dropout']\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=ModelConfig.TRAINING_PARAMS['learning_rate']),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7bbaf7-7618-4eaf-8c9f-a72f71c02286",
   "metadata": {},
   "source": [
    "## 4.2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f84134a-198c-4bbd-9c2c-9ba032edd90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create a dictionary to store timing metrics\n",
    "timing_metrics = {\n",
    "    'training_time': 0,\n",
    "    'prediction_time': 0,\n",
    "    'total_time': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "349c29d7-833c-4b4b-b88f-dd7b34ac06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 0.0033 - val_mae: 0.0403\n",
      "Epoch 2/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 1.3108e-04 - mae: 0.0076 - val_loss: 0.0032 - val_mae: 0.0399\n",
      "Epoch 3/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 1.2761e-04 - mae: 0.0073 - val_loss: 0.0029 - val_mae: 0.0367\n",
      "Epoch 4/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 1.0933e-04 - mae: 0.0070 - val_loss: 0.0018 - val_mae: 0.0299\n",
      "Epoch 5/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 1.1257e-04 - mae: 0.0073 - val_loss: 0.0025 - val_mae: 0.0338\n",
      "Epoch 6/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 9.4342e-05 - mae: 0.0061 - val_loss: 0.0031 - val_mae: 0.0389\n",
      "Epoch 7/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 7.7443e-05 - mae: 0.0055 - val_loss: 0.0028 - val_mae: 0.0364\n",
      "Epoch 8/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 7.9868e-05 - mae: 0.0056 - val_loss: 0.0024 - val_mae: 0.0332\n",
      "Epoch 9/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - loss: 7.4773e-05 - mae: 0.0055 - val_loss: 0.0029 - val_mae: 0.0371\n",
      "Epoch 10/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 7.5540e-05 - mae: 0.0056 - val_loss: 0.0020 - val_mae: 0.0298\n",
      "Epoch 11/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 7.6784e-05 - mae: 0.0054 - val_loss: 0.0051 - val_mae: 0.0519\n",
      "Epoch 12/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - loss: 6.8946e-05 - mae: 0.0052 - val_loss: 0.0050 - val_mae: 0.0517\n",
      "Epoch 13/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 6.8525e-05 - mae: 0.0052 - val_loss: 0.0023 - val_mae: 0.0327\n",
      "Epoch 14/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - loss: 7.0338e-05 - mae: 0.0053 - val_loss: 0.0069 - val_mae: 0.0617\n",
      "Epoch 15/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 6.3539e-05 - mae: 0.0050 - val_loss: 0.0063 - val_mae: 0.0584\n",
      "Epoch 16/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - loss: 6.6996e-05 - mae: 0.0055 - val_loss: 0.0051 - val_mae: 0.0506\n",
      "Epoch 17/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 6.4913e-05 - mae: 0.0051 - val_loss: 0.0035 - val_mae: 0.0410\n",
      "Epoch 18/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - loss: 6.4406e-05 - mae: 0.0051 - val_loss: 0.0072 - val_mae: 0.0643\n",
      "Epoch 19/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - loss: 7.8820e-05 - mae: 0.0055 - val_loss: 0.0033 - val_mae: 0.0404\n",
      "Epoch 20/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - loss: 5.8050e-05 - mae: 0.0048 - val_loss: 0.0025 - val_mae: 0.0347\n",
      "Epoch 21/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - loss: 5.8478e-05 - mae: 0.0047 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 22/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 5.6102e-05 - mae: 0.0049 - val_loss: 0.0046 - val_mae: 0.0480\n",
      "Epoch 23/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 5.7693e-05 - mae: 0.0047 - val_loss: 0.0036 - val_mae: 0.0420\n",
      "Epoch 24/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 5.2323e-05 - mae: 0.0045 - val_loss: 0.0061 - val_mae: 0.0575\n",
      "Epoch 25/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 5.0950e-05 - mae: 0.0046 - val_loss: 0.0041 - val_mae: 0.0448\n",
      "Epoch 26/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 4.8272e-05 - mae: 0.0046 - val_loss: 0.0036 - val_mae: 0.0420\n",
      "Epoch 27/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 5.8056e-05 - mae: 0.0048 - val_loss: 0.0042 - val_mae: 0.0459\n",
      "Epoch 28/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - loss: 5.1541e-05 - mae: 0.0046 - val_loss: 0.0039 - val_mae: 0.0441\n",
      "Epoch 29/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - loss: 6.0293e-05 - mae: 0.0048 - val_loss: 0.0046 - val_mae: 0.0477\n",
      "Epoch 30/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - loss: 5.3129e-05 - mae: 0.0046 - val_loss: 0.0063 - val_mae: 0.0581\n",
      "Epoch 31/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 5.2893e-05 - mae: 0.0046 - val_loss: 0.0078 - val_mae: 0.0658\n",
      "Epoch 32/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 4.8868e-05 - mae: 0.0044 - val_loss: 0.0047 - val_mae: 0.0490\n",
      "Epoch 33/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 4.6645e-05 - mae: 0.0043 - val_loss: 0.0054 - val_mae: 0.0537\n",
      "Epoch 34/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 5.0841e-05 - mae: 0.0046 - val_loss: 0.0038 - val_mae: 0.0436\n",
      "Epoch 35/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 5.5248e-05 - mae: 0.0046 - val_loss: 0.0037 - val_mae: 0.0427\n",
      "Epoch 36/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 4.1960e-05 - mae: 0.0042 - val_loss: 0.0041 - val_mae: 0.0453\n",
      "Epoch 37/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 5.1692e-05 - mae: 0.0048 - val_loss: 0.0042 - val_mae: 0.0462\n",
      "Epoch 38/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 4.4507e-05 - mae: 0.0044 - val_loss: 0.0038 - val_mae: 0.0431\n",
      "Epoch 39/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 3.7496e-05 - mae: 0.0041 - val_loss: 0.0029 - val_mae: 0.0381\n",
      "Epoch 40/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - loss: 5.0471e-05 - mae: 0.0049 - val_loss: 0.0063 - val_mae: 0.0580\n",
      "Epoch 41/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - loss: 5.7817e-05 - mae: 0.0051 - val_loss: 0.0067 - val_mae: 0.0606\n",
      "Epoch 42/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - loss: 4.9921e-05 - mae: 0.0045 - val_loss: 0.0038 - val_mae: 0.0436\n",
      "Epoch 43/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 4.3140e-05 - mae: 0.0043 - val_loss: 0.0043 - val_mae: 0.0469\n",
      "Epoch 44/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 3.7877e-05 - mae: 0.0041 - val_loss: 0.0029 - val_mae: 0.0373\n",
      "Epoch 45/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 4.2679e-05 - mae: 0.0044 - val_loss: 0.0035 - val_mae: 0.0413\n",
      "Epoch 46/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 5.2465e-05 - mae: 0.0046 - val_loss: 0.0031 - val_mae: 0.0387\n",
      "Epoch 47/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 6.0317e-05 - mae: 0.0053 - val_loss: 0.0044 - val_mae: 0.0473\n",
      "Epoch 48/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 4.2940e-05 - mae: 0.0042 - val_loss: 0.0065 - val_mae: 0.0594\n",
      "Epoch 49/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 4.6548e-05 - mae: 0.0044 - val_loss: 0.0060 - val_mae: 0.0565\n",
      "Epoch 50/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 120ms/step - loss: 4.7943e-05 - mae: 0.0045 - val_loss: 0.0043 - val_mae: 0.0463\n",
      "Epoch 51/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 4.6489e-05 - mae: 0.0043 - val_loss: 0.0038 - val_mae: 0.0435\n",
      "Epoch 52/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 4.2555e-05 - mae: 0.0043 - val_loss: 0.0052 - val_mae: 0.0527\n",
      "Epoch 53/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 4.7280e-05 - mae: 0.0043 - val_loss: 0.0050 - val_mae: 0.0509\n",
      "Epoch 54/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 4.6689e-05 - mae: 0.0044 - val_loss: 0.0046 - val_mae: 0.0491\n",
      "Epoch 55/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 4.1565e-05 - mae: 0.0043 - val_loss: 0.0047 - val_mae: 0.0498\n",
      "Epoch 56/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 4.4296e-05 - mae: 0.0046 - val_loss: 0.0035 - val_mae: 0.0410\n",
      "Epoch 57/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 4.0455e-05 - mae: 0.0042 - val_loss: 0.0059 - val_mae: 0.0567\n",
      "Epoch 58/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 5.0287e-05 - mae: 0.0046 - val_loss: 0.0033 - val_mae: 0.0402\n",
      "Epoch 59/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 4.3519e-05 - mae: 0.0042 - val_loss: 0.0039 - val_mae: 0.0449\n",
      "Epoch 60/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 3.6545e-05 - mae: 0.0043 - val_loss: 0.0027 - val_mae: 0.0354\n",
      "Epoch 61/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 4.5333e-05 - mae: 0.0044 - val_loss: 0.0023 - val_mae: 0.0330\n",
      "Epoch 62/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 5.9021e-05 - mae: 0.0046 - val_loss: 0.0061 - val_mae: 0.0577\n",
      "Epoch 63/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 4.0947e-05 - mae: 0.0042 - val_loss: 0.0022 - val_mae: 0.0320\n",
      "Epoch 64/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 4.9118e-05 - mae: 0.0046 - val_loss: 0.0052 - val_mae: 0.0536\n",
      "Epoch 65/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 3.6157e-05 - mae: 0.0041 - val_loss: 0.0038 - val_mae: 0.0438\n",
      "Epoch 66/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 4.2881e-05 - mae: 0.0044 - val_loss: 0.0037 - val_mae: 0.0429\n",
      "Epoch 67/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 4.4156e-05 - mae: 0.0044 - val_loss: 0.0043 - val_mae: 0.0467\n",
      "Epoch 68/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 3.9275e-05 - mae: 0.0041 - val_loss: 0.0051 - val_mae: 0.0517\n",
      "Epoch 69/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 4.1041e-05 - mae: 0.0043 - val_loss: 0.0051 - val_mae: 0.0521\n",
      "Epoch 70/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 4.9534e-05 - mae: 0.0045 - val_loss: 0.0034 - val_mae: 0.0407\n",
      "Epoch 71/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 4.6027e-05 - mae: 0.0044 - val_loss: 0.0031 - val_mae: 0.0391\n",
      "Epoch 72/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 3.9687e-05 - mae: 0.0041 - val_loss: 0.0041 - val_mae: 0.0460\n",
      "Epoch 73/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 4.1039e-05 - mae: 0.0041 - val_loss: 0.0034 - val_mae: 0.0416\n",
      "Epoch 74/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 3.8713e-05 - mae: 0.0042 - val_loss: 0.0085 - val_mae: 0.0717\n",
      "Epoch 75/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 5.7461e-05 - mae: 0.0049 - val_loss: 0.0048 - val_mae: 0.0513\n",
      "Epoch 76/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 3.7962e-05 - mae: 0.0041 - val_loss: 0.0034 - val_mae: 0.0415\n",
      "Epoch 77/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 4.3799e-05 - mae: 0.0043 - val_loss: 0.0026 - val_mae: 0.0350\n",
      "Epoch 78/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 4.0892e-05 - mae: 0.0043 - val_loss: 0.0042 - val_mae: 0.0468\n",
      "Epoch 79/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 4.6140e-05 - mae: 0.0043 - val_loss: 0.0027 - val_mae: 0.0362\n",
      "Epoch 80/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 4.5116e-05 - mae: 0.0044 - val_loss: 0.0039 - val_mae: 0.0441\n",
      "Epoch 81/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 4.2596e-05 - mae: 0.0043 - val_loss: 0.0035 - val_mae: 0.0419\n",
      "Epoch 82/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 4.2612e-05 - mae: 0.0043 - val_loss: 0.0043 - val_mae: 0.0468\n",
      "Epoch 83/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 4.7348e-05 - mae: 0.0044 - val_loss: 0.0073 - val_mae: 0.0660\n",
      "Epoch 84/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 4.3545e-05 - mae: 0.0045 - val_loss: 0.0035 - val_mae: 0.0415\n",
      "Epoch 85/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 3.8907e-05 - mae: 0.0042 - val_loss: 0.0031 - val_mae: 0.0385\n",
      "Epoch 86/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 4.5722e-05 - mae: 0.0046 - val_loss: 0.0043 - val_mae: 0.0467\n",
      "Epoch 87/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 4.2705e-05 - mae: 0.0045 - val_loss: 0.0033 - val_mae: 0.0405\n",
      "Epoch 88/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 3.9508e-05 - mae: 0.0042 - val_loss: 0.0049 - val_mae: 0.0515\n",
      "Epoch 89/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 4.0535e-05 - mae: 0.0042 - val_loss: 0.0026 - val_mae: 0.0354\n",
      "Epoch 90/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 5.1200e-05 - mae: 0.0047 - val_loss: 0.0038 - val_mae: 0.0446\n",
      "Epoch 91/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 4.1419e-05 - mae: 0.0043 - val_loss: 0.0032 - val_mae: 0.0394\n",
      "Epoch 92/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 4.1735e-05 - mae: 0.0044 - val_loss: 0.0047 - val_mae: 0.0503\n",
      "Epoch 93/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 4.1635e-05 - mae: 0.0042 - val_loss: 0.0040 - val_mae: 0.0449\n",
      "Epoch 94/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 4.2602e-05 - mae: 0.0044 - val_loss: 0.0032 - val_mae: 0.0398\n",
      "Epoch 95/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 3.9261e-05 - mae: 0.0041 - val_loss: 0.0034 - val_mae: 0.0413\n",
      "Epoch 96/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 5.1345e-05 - mae: 0.0050 - val_loss: 0.0040 - val_mae: 0.0456\n",
      "Epoch 97/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 4.0066e-05 - mae: 0.0042 - val_loss: 0.0045 - val_mae: 0.0490\n",
      "Epoch 98/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 3.8232e-05 - mae: 0.0043 - val_loss: 0.0035 - val_mae: 0.0419\n",
      "Epoch 99/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 4.8607e-05 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0393\n",
      "Epoch 100/100\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - loss: 4.3521e-05 - mae: 0.0042 - val_loss: 0.0029 - val_mae: 0.0377\n"
     ]
    }
   ],
   "source": [
    "# Training with timing\n",
    "print(\"Starting model training...\")\n",
    "training_start = time.time()\n",
    "\n",
    "#Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=ModelConfig.TRAINING_PARAMS['epochs'],\n",
    "    batch_size=ModelConfig.TRAINING_PARAMS['batch_size'],\n",
    "    validation_split=ModelConfig.TRAINING_PARAMS['validation_split'],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e556d039-2581-40fd-aa5b-477cf0de7f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end = time.time()\n",
    "timing_metrics['training_time'] = training_end - training_start\n",
    "\n",
    "model_metrics = {\n",
    "    # Runtime metrics\n",
    "    'training_time': training_end - training_start,\n",
    "    \n",
    "    # Training history\n",
    "    'history': history.history,  # including loss, mae\n",
    "    \n",
    "    # Final metrics\n",
    "    'final_metrics': {\n",
    "        'mae': history.history['mae'][-1],          # Mean Absolute Error\n",
    "        'val_mae': history.history['val_mae'][-1],  # Validation MAE\n",
    "        'mape': history.history['mape'][-1] if 'mape' in history.history else None,  # MAPE if available\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "729c7802-ac1e-4910-9d03-7d39fbfa7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in 1131.97 seconds\n"
     ]
    }
   ],
   "source": [
    "# save model and trainning time\n",
    "model.save('../models/lstm_model.keras')\n",
    "joblib.dump(history.history, '../models/training_history.pkl')\n",
    "joblib.dump(timing_metrics, '../models/training_metrics.pkl')\n",
    "\n",
    "print(f\"\\nTraining completed in {timing_metrics['training_time']:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
